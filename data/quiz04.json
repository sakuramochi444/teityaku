[
  {
    "type": "single-choice",
    "question": "生理学的なニューラルネットワークにおける「ニューロンによる信号伝達」に関する説明として最も適切なものはどれか。記号で答えよ。",
    "options": [
      "ニューロンは、隣接するニューロンから励起性の信号を受け取ると発火し、抑制性の信号を受け取ると発火が中止される。",
      "ニューロンは、隣接するニューロンから信号を受け取ると約10ms以内に発火する。",
      "ニューロンは、隣接するニューロンから信号を受け取ると累積的に電位が変化し、その電位が閾値を超えると発火する。",
      "ニューロンは、隣接する全てのニューロンから信号を受け取ったとき発火する。",
      "ニューロンは、隣接するいずれかのニューロンから信号を受け取ったとき発火する。"
    ],
    "answer": 2,
    "explanation": "生理学的なニューロンは、他のニューロンから受け取った信号（シナプス入力）によって細胞膜の電位を変化させます。励起性（興奮性）の信号は電位を上昇させ、抑制性（抑制性）の信号は電位を下降させます。これらの信号が合算され、膜電位がある一定の「閾値」を超えると、ニューロンは活動電位（スパイク）を発生させ、それが「発火」として他のニューロンに信号を伝達します。"
  },
  {
    "type": "single-choice",
    "question": "生理学的なニューラルネットワークの構造に関する説明として最も適切なものはどれか。記号で答えよ。",
    "options": [
      "ニューロンは基本的に1対1で双方向に接続されている。",
      "ニューロンは基本的に1対1で単方向に接続されている。",
      "ニューロンは基本的に複数のニューロンと単方向で接続されている。",
      "ニューロンは基本的に複数のニューロンと双方向で接続されている。"
    ],
    "answer": 2,
    "explanation": "生理学的なニューラルネットワークでは、一つのニューロンは樹状突起を介して多数の他のニューロンから信号を受け取り、軸索を通じて複数の他のニューロンへと信号を伝達します。この信号伝達は、シナプスを介して基本的に一方向（単方向）に行われます。つまり、信号は前シナプスニューロンから後シナプスニューロンへと流れます。"
  },
  {
    "type": "single-choice",
    "question": "生理学的なニューラルネットワークにおける信号伝達に関して正しい説明はどれか。最も適切なものを選び記号で答えよ。",
    "options": [
      "あるニューロンから他のニューロンに伝達される信号の強度は常に均一である。",
      "あるニューロンから他のニューロンに伝達される信号のタイプ（励起性or抑制性）は全て同じである。",
      "ニューロンは受け取ったすべての信号を同じ強度で隣接するニューロンに伝える。",
      "ニューロンは励起性の信号を受け取ると電位が上がり、抑制性の信号を受け取ると電位が下がる。",
      "ニューロンは発火しているときに励起性の信号を伝え、そうでないときには抑制性の信号を伝える。"
    ],
    "answer": 3,
    "explanation": "ニューロンが他のニューロンから信号を受け取る際、その信号が励起性（興奮性）であれば細胞膜の電位を上昇させ、閾値に近づけます。一方、抑制性（抑制性）の信号であれば電位を下降させ、閾値から遠ざけます。このように、ニューロンは受け取る信号のタイプによって膜電位を異なる方向に変化させ、最終的にその総和が発火するかどうかを決定します。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークの文脈においてMLPとは何の略語か。最も適切なものを選び記号で答えよ。",
    "options": [
      "Modern Learning Protocol",
      "Multi-Layer Perceptron",
      "Multiple Linear Programs",
      "Memory Layer Protocol"
    ],
    "answer": 1,
    "explanation": "MLPは「Multi-Layer Perceptron（多層パーセプトロン）」の略語です。これは、複数の隠れ層を持つフィードフォワード型ニューラルネットワークの基本的な構造を指します。各層のパーセプトロン（ニューロン）が前の層の出力を受け取り、活性化関数を通じて次の層へと信号を伝達することで、複雑なパターン認識や関数近似を行うことができます。"
  },
  {
    "type": "single-choice",
    "question": "ChatGPTの基盤となるTransformerモデルが使用する特徴的なメカニズム（機構）はどれか。最も適切なものを選び記号で答えよ。",
    "options": [
      "Self-Attention",
      "Recurrent Units",
      "Gate Layers",
      "Perceptron Relays"
    ],
    "answer": 0,
    "explanation": "ChatGPTなどの大規模言語モデルの基盤となっているTransformerモデルの最も特徴的なメカニズムは「Self-Attention（自己注意機構）」です。この機構により、モデルは入力シーケンス内の異なる位置にある単語間の関係性を効率的に捉え、文脈に応じた重要な情報を重み付けして処理することができます。これにより、従来のRNN（Recurrent Neural Network）が抱えていた長距離依存性の問題が大きく改善されました。"
  },
  {
    "type": "single-choice",
    "question": "次のうち、ディープラーニング（深層学習）には属さないモデルはどれか。最も適切なものを選び記号で答えよ。",
    "options": [
      "MLP",
      "CNN",
      "SVM",
      "RNN",
      "LSTM",
      "Transformer"
    ],
    "answer": 2,
    "explanation": "ディープラーニングは、多層のニューラルネットワークを用いることで、データから自動的に特徴量を学習する機械学習の一分野です。MLP（多層パーセプトロン）、CNN（畳み込みニューラルネットワーク）、RNN（再帰型ニューラルネットワーク）、LSTM（Long Short-Term Memory）、Transformerは全てディープラーニングの代表的なモデルです。一方、**SVM（サポートベクターマシン）** は、サポートベクトルとマージンに基づいてデータを分類する強力な機械学習アルゴリズムですが、ニューラルネットワークを基盤としない**従来型の機械学習モデル**に分類されます。"
  },
  {
    "type": "single-choice",
    "question": "畳み込みニューラルネットワークが得意とする領域（タスク）はどれか。最も適切なものを選び記号で答えよ。",
    "options": [
      "シーケンスデータの処理",
      "画像データの処理",
      "文章（テキストデータ）の処理",
      "動画データの処理",
      "非構造化データの処理"
    ],
    "answer": 1,
    "explanation": "畳み込みニューラルネットワーク（CNN）は、画像認識のために特に設計されたニューラルネットワークのタイプです。畳み込み層が局所的な特徴（エッジ、パターンなど）を抽出し、プーリング層が空間的な情報を集約することで、画像内の特徴を効率的に学習します。この構造により、画像分類、物体検出、画像生成など、**画像データの処理**において非常に高い性能を発揮します。動画データ処理にも応用されますが、その場合も各フレームを画像として処理する要素が含まれます。"
  },
  {
    "question": "次のうち、「音声認識」に最も適するニューラルネットワークモデルはどれか。また「画像認識」に最も適するニューラルネットワークモデルはどれか。<br>① Multi-Layer Perceptron<br>② Convolutional Neural Network<br>③ Recurrent Neural Network<br>④ Generative Adversarial Network",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["3", "③"],
      ["2", "②"]
    ],
    "required_groups": 2,
    "explanation": "音声認識には、**Recurrent Neural Network（RNN）**が適しています。RNNは、時系列データやシーケンスデータの処理に優れており、音声のような連続的なデータを扱うのに適しています。一方、画像認識には、**Convolutional Neural Network（CNN）**が最も適しています。CNNは、画像内の局所的なパターンを捉えるために設計されており、画像分類や物体検出などのタスクで高い性能を発揮します。"
  },
  {
    "question": "16×16 ピクセルのグレースケール画像を用いて、トランプのスート（スペード／クラブ／ハート／ダイヤ）の分類をしたい。MLPでモデルを構成するにあたり、「入力層」には何個のニューロンを配置すべきか答えよ。また「出力層」には何個のニューロンを配置すべきか答えよ。",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["256"],
      ["4"]
    ],
    "required_groups": 2,
    "explanation": "入力層には、画像の各ピクセルを表すニューロンが必要です。16×16 ピクセルのグレースケール画像では、合計で256ピクセルが存在するため、入力層には**256個のニューロン**を配置します。出力層には、分類したいスートの数に応じてニューロンを配置します。トランプのスートはスペード、クラブ、ハート、ダイヤの4種類であるため、出力層には**4個のニューロン**を配置します。"
  },
  {
    "question": "50×50 ピクセルの衛星画像（グレースケール画像）を用いて、その地域の植生密度を0％から100％の範囲で予測する場合、MLPでモデルを構成するにあたり、「入力層」には何個のニューロンを配置すべきか答えよ。また「出力層」には何個のニューロンを配置すべきか答えよ。",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["2500"],
      ["1"]
    ],
    "required_groups": 2,
    "explanation": "入力層には、画像の各ピクセルを表すニューロンが必要です。50×50 ピクセルのグレースケール画像では、合計で2500ピクセルが存在するため、入力層には**2500個のニューロン**を配置します。出力層には、植生密度を0％から100％の範囲で予測するため、1つの連続値を出力する必要があります。そのため、出力層には**1個のニューロン**を配置します。"
  },
  {
    "question": "40×40 ピクセルの気象レーダー画像（グレースケール画像）を用いて今後1時間の「降水量」と「落雷発生確率」を予測したい。MLPでモデルを構成するにあたり、「入力層」には何個のニューロンを配置すべきか答えよ。また「出力層」には何個のニューロンを配置すべきか答えよ。",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["1600"],
      ["2"]
    ],
    "required_groups": 2,
    "explanation": "入力層には、画像の各ピクセルを表すニューロンが必要です。40×40 ピクセルのグレースケール画像では、合計で1600ピクセルが存在するため、入力層には**1600個のニューロン**を配置します。出力層には、降水量と落雷発生確率の2つの予測値を出力する必要があります。そのため、出力層には**2個のニューロン**を配置します。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークに対する入力（特徴量）として「気温」を用いるとき、これに推奨される前処理はどれか。最も適切なものを記号で答えよ。",
    "options": [
      "二値化",
      "正規化",
      "正則化",
      "One-hotエンコーディング"
    ],
    "answer": 1,
    "explanation": "「気温」のような連続的な数値データは、そのままニューラルネットワークに入力すると、値の範囲が広すぎたり、他の特徴量とのスケールの違いによって学習が不安定になったりする可能性があります。そのため、一般的には**正規化（Normalization）** を行い、データの値を特定の範囲（例えば0から1、または平均0・標準偏差1）にスケーリングすることが推奨されます。これにより、学習が安定し、モデルの収束が速まることが期待できます。二値化は連続値を2つのカテゴリに変換するもので、One-hotエンコーディングはカテゴリカルデータを数値に変換する手法です。正則化は過学習を防ぐための手法であり、前処理とは異なります。"
  },
  {
    "type": "single-choice",
    "question": "次の特徴量のうち、ニューラルネットワークの入力として用いる際にOne-hotエンコーディングが推奨されるものはどれか。最も適切なものを記号で答えよ。",
    "options": [
      "血圧",
      "心拍数",
      "血液型",
      "輸血経験の有無",
      "生物学的な性別"
    ],
    "answer": 2,
    "explanation": "**One-hotエンコーディング**は、カテゴリカルデータ（名義尺度）を数値データに変換するための一般的な前処理手法です。カテゴリカルデータは、数値的な順序や大小関係を持たないため、そのまま数値としてモデルに入力すると誤った解釈をされる可能性があります。「血液型」（A型、B型、O型、AB型など）は、それぞれの間に数値的な順序関係がない名義尺度であり、One-hotエンコーディングによって各カテゴリを独立したバイナリ特徴量として表現することが適切です。血圧や心拍数は連続値、輸血経験の有無や生物学的な性別は二値データとして扱われることが多いです。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークに用いる特徴量に対する前処理としての「正規化」について適切に説明しているものはどれか。最も適切なものを記号で答えよ。",
    "options": [
      "特徴量の値をバイナリ（0または1）に変換する処理",
      "特徴量の尺度を変更せず、データの平均を0にする処理",
      "特徴量から異常値（外れ値）を除去する処理",
      "特徴量の範囲を0.0から1.0にスケーリングする処理"
    ],
    "answer": 3,
    "explanation": "ニューラルネットワークにおける**正規化（Normalization）** の主な目的の一つは、各特徴量の値を特定の範囲（例えば、最小値を0、最大値を1とする**0.0から1.0の範囲**）にスケーリングすることです。これにより、異なるスケールの特徴量が混在していても、勾配降下法などの最適化アルゴリズムが安定して機能し、学習効率が向上します。選択肢②の「平均を0にする処理」は「標準化（Standardization）」に含まれることもありますが、一般的に「正規化」は値の範囲を特定のスケーリングに変換することを指します。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークに入力する特徴量の前処理として、常にOne-hotエンコーディングが推奨されるものはどれか。最も適切なものを記号で答えよ。",
    "options": [
      "名義尺度に属する情報",
      "順序尺度に属する情報",
      "間隔尺度に属する情報",
      "比例尺度に属する情報"
    ],
    "answer": 0,
    "explanation": "**One-hotエンコーディング**は、カテゴリカルデータの中でも特に**名義尺度**（Nominal Scale）に属する情報を扱う際に強く推奨されます。名義尺度は、カテゴリ間に順序や大小関係がないデータ（例：血液型、色、都市名）です。これらをそのまま数値に変換すると、モデルが誤った数値的な関係性（例：A型がB型より大きいといった関係）を学習してしまう可能性があるため、各カテゴリを独立したバイナリベクトルとして表現するOne-hotエンコーディングが有効です。順序尺度（例：満足度、学歴）の場合は、その順序関係を保つために別のエンコーディング手法が使われることもあります。"
  },
  {
    "type": "single-choice",
    "question": "MLPによる深層学習に「画像」を特徴量として用いる場合、一般に必要となる前処理はどれか。最も適切なものを記号で答えよ。",
    "options": [
      "色の反転",
      "平坦化と正規化",
      "カラーフィルタの適用",
      "高解像度化"
    ],
    "answer": 1,
    "explanation": "MLP（多層パーセプトロン）は、入力が一次元のベクトル形式であることを前提としています。画像は通常、幅×高さ×チャンネル数（例：28x28x1のグレースケール画像）といった多次元のデータ構造を持っています。そのため、MLPに入力する際には、この多次元データを一次元のベクトルに変換する**平坦化（Flattening）** の処理が必要です。また、画素値の範囲が0から255のような場合、学習を安定させるために、これらの値を0から1の範囲にスケーリングする**正規化（Normalization）** も一般的に行われます。色の反転やカラーフィルタの適用はタスクによっては行われますが、一般的な前処理ではありません。高解像度化はデータの複雑性を増すため、通常は行いません。"
  },
  {
  "type": "simple",
  "question": "MLPによる深層学習に32×32ピクセルのカラー画像を平坦化して用いる場合、入力層に必要なニューロンの数はいくつか。",
  "answers": [
    "3072個",
    "3072"
  ],
  "explanation": "32×32ピクセルのカラー画像は、各ピクセルがRGBの3色チャンネルを持つため、1枚の画像は32×32×3 = 3072個の値を持ちます。MLPに入力する際には、この画像を1次元のベクトルに変換する必要があり、そのためには3072個のニューロンが入力層に必要となります。"
  },
  {
    "type": "single-choice",
    "question": "深層学習に用いる画像の前処理としてRGBをHSVに変換するメリットは何か。最も適切なものを記号で答えよ。",
    "options": [
      "画像を構成するピクセル数を減らすことができる",
      "透過情報を扱うことができる",
      "画像ファイルのサイズを小さくすることができる",
      "色情報をより人間の視覚に即した形で表現できる",
      "画像のコントラストを高めることができる"
    ],
    "answer": 3,
    "explanation": "RGB（Red, Green, Blue）は光の三原色に基づいた色空間ですが、色相（Hue）、彩度（Saturation）、明度（Value/Brightness）で色を表現するHSV色空間は、人間の色の知覚に近い形で色情報を表現できます。特に、色相（H）は照明の変化に比較的影響されにくいため、画像認識タスクにおいて、物体の色を安定して識別する必要がある場合に有効な前処理となります。ピクセル数やファイルサイズ、透過情報、コントラストは直接的な変換メリットではありません。"
  },
  {
    "type": "single-choice",
    "question": "画像を特徴量に用いる機械学習において、高解像度の画像を使用するメリットまたはデメリットに関する説明として不適切なものはどれか。記号で1つ答えよ。",
    "options": [
      "高解像度の画像は情報量が多く、物体の特徴をより精密に抽出可能なため、認識精度が向上する可能性がある。",
      "高解像度の画像はファイルサイズが大きくなるため、学習に必要な計算資源や時間が増加する。",
      "高解像度の画像を使用することで、学習に必要な画像の枚数を減らすことができる。",
      "高解像度の画像は、複雑なテクスチャや細かいディテールを含むことが多いため、場合によっては過学習を引き起こす可能性がある。"
    ],
    "answer": 2,
    "explanation": "高解像度の画像は、より多くの詳細情報を含むため、モデルの認識精度が向上する可能性や、過学習のリスクが高まる可能性があります。また、ファイルサイズが大きくなり、学習に必要な計算資源や時間が増加するのは事実です。しかし、高解像度の画像を使うことによって、**学習に必要な画像の枚数が減るという直接的な関係はありません**。モデルの性能を確保するためには、高解像度であっても十分な量のデータが必要となります。"
  },
  {
    "type": "multiple-choice",
    "question": "MLPを使用した機械学習の「学習フェーズ」において、誤差逆伝播法など通じて最適化するパラメータは次のうちどれか。該当するものをすべて答えよ。",
    "options": [
      "特徴量（入力値）",
      "中間層の層数と、各中間層を構成するニューロンの数",
      "各ニューロンのバイアス",
      "各ニューロンの出力値",
      "各ニューロン間の重み係数",
      "予測値（出力値）"
    ],
    "answer": [
      2,
      5
    ],
    "explanation": "MLP（多層パーセプトロン）を使用した機械学習の学習フェーズでは、モデルのパラメータである**各ニューロン間の重み係数**と**各ニューロンのバイアス**が最適化されます。誤差逆伝播法は、出力層から入力層に向かって誤差を逆伝播させることで、これらのパラメータを更新します。特徴量（入力値）や予測値（出力値）はモデルの入力と出力であり、学習フェーズで直接最適化されるものではありません。中間層の層数やニューロンの数はモデルの設計に関わるものであり、学習フェーズで変化するものではありません。"
  },
  {
  "type": "simple",
  "question": "784個のニューロンからなる入力層、16個のニューロンからなる中間層1、16個のニューロンからなる中間層2、10個のニューロンからなる出力層を持ち、各層が全結合されているMLPにおいて、学習フェーズで最適化するパラメータの数はいくつか。",
  "answers": [
    "13002"
  ],
  "explanation": "このMLPの各層間の重み係数とバイアスを計算します。\n\n1. 入力層から中間層1への重み係数: 784 * 16 = 12544\n2. 中間層1から中間層2への重み係数: 16 * 16 = 256\n3. 中間層2から出力層への重み係数: 16 * 10 = 160\n4. 中間層1のバイアス: 16\n5. 中間層2のバイアス: 16\n6. 出力層のバイアス: 10\n\n合計すると、12544 + 256 + 160 + 16 + 16 + 10 = **13002**となります。"
  },
  {
    "type": "essay",
    "question": "次の図に示すニューラルネットワークにおいて、Layer 1の0番目のニューロンの出力値 𝑎0(1)を数式で示せ。Layer 1の0番目のニューロンのバイアスを 𝑏0 、活性化関数を 𝑓 として答えること。",
    "image": "./images/4-1.png",
    "exampleAnswer": "a0=f(w0,0a0(0)+w0,1a1(0)+w0,2a2(0)+b0",
    "explanation": "この問題は自己採点です。あなたの回答が正しいかどうか、模範解答を参考に確認してみましょう。"
  },
  {
    "question": "ニューラルネットワークの活性化関数として使用されるReLU関数を表したものはどれか。また、シグモイド関数を表したものはどれか。記号で答えよ。/n① 𝑓(𝑥)=max(0,𝑥)/n② 𝑓(𝑥)=min(0,𝑥)/n③ 𝑓(𝑥)=(1+𝑒^(−𝑥))^(−1)/n④ 𝑓(𝑥)=(1−𝑒^(−𝑥))^(−1)",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["1", "①"],
      ["3", "③"]
    ],
    "required_groups": 2,
    "explanation": "ReLU（Rectified Linear Unit）関数は、入力が0以下のときは0を出力し、0より大きいときはそのままの値を出力する活性化関数です。これは、選択肢①の「𝑓(𝑥)=max(0,𝑥)」で表されます。一方、シグモイド関数は、入力値を0から1の範囲に圧縮するS字型の関数で、選択肢③の「𝑓(𝑥)=(1+𝑒^(−𝑥))^(−1)」で表されます。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークにおける「重み係数」と「バイアス」が取りうる数値の範囲について、正しい説明をしているものはどれか。最も適切なものを記号で答えよ。",
    "options": [
      "重み係数は0以上の実数のみをとる、バイアスも0以上の実数のみをとる。",
      "重み係数もバイアスも任意の実数をとる。",
      "重み係数は0以上の実数のみをとるが、バイアスは任意の実数をとる。",
      "重み係数は任意の実数をとるが、バイアスは0以上の実数のみをとる。"
    ],
    "answer": 1,
    "explanation": "ニューラルネットワークにおける「重み係数（weights）」と「バイアス（bias）」は、入力信号の重要度を調整し、モデルの出力に影響を与えるパラメータです。これらの値は、正負どちらの実数も取り得ます。重み係数は入力信号を強調または抑制し、バイアスはニューロンの発火しやすさを調整します。これらの値が任意の実数をとることで、モデルは様々な複雑な関数を学習し表現できるようになります。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークの学習に使用される「誤差逆伝播法」に最も関連深い数学の分野はどれか。最も適切なものを記号で答えよ。",
    "options": [
      "確率",
      "統計",
      "偏微分",
      "重積分",
      "複素数",
      "幾何学"
    ],
    "answer": 2,
    "explanation": "ニューラルネットワークの学習アルゴリズムである「誤差逆伝播法（Backpropagation）」は、出力層から入力層へ誤差を逆方向に伝播させながら、各層の重みとバイアスを更新する手法です。この際に、モデルの出力と正解との誤差を最小化するために、**勾配降下法**が用いられます。勾配は、各パラメータに対する誤差関数の変化率を示すものであり、これは**偏微分**によって計算されます。したがって、誤差逆伝播法は偏微分と密接に関連しています。"
  },
  {
    "type": "single-choice",
    "question": "ニューラルネットワークにおける活性化関数の主たる役割はなにか。最も適切なものを記号で答えよ。",
    "options": [
      "誤差逆伝播法を適用する際、誤差勾配を効率的に伝播させる。",
      "各層の出力を正規分布に近似させる。",
      "ニューラルネットワークに非線形性を導入する。",
      "ニューロンの出力を特定の範囲内に収める。"
    ],
    "answer": 2,
    "explanation": "ニューラルネットワークにおける**活性化関数（Activation Function）** の最も重要な役割は、各ニューロンの出力に**非線形性**を導入することです。もし活性化関数が線形であった場合、多層のニューラルネットワークも結局は線形モデルと等価になってしまい、複雑な非線形関係を持つデータを学習することができません。非線形性を導入することで、ニューラルネットワークはより複雑なパターンや関係性をモデル化し、多様な問題に対応できるようになります。"
  },
  {
    "type": "single-choice",
    "question": "非線形の活性化関数を使用しないMLPは、どのようなモデルと等価といえるか。最も適切なものを記号で答えよ。",
    "options": [
      "単層ニューラルネットワーク",
      "線形重回帰モデル",
      "多変量線形回帰モデル",
      "単一の線形分類器",
      "サポートベクターマシン"
    ],
    "answer": 1,
    "explanation": "MLP（多層パーセプトロン）がもし非線形の活性化関数を使用せず、線形の変換のみを行う場合、層をいくら重ねても、それらの線形変換の組み合わせは最終的に**単一の線形変換**として表現できてしまいます。つまり、多層であっても線形モデルとしてしか機能しません。これは本質的に**線形重回帰モデル**と等価であると言えます。したがって、ニューラルネットワークが複雑な非線形パターンを学習するためには、非線形の活性化関数が不可欠です。"
  },
  {
    "question": "ニューラルネットワークの活性化関数として使用されるReLU関数を表したものはどれか。また、シグモイド関数を表したものはどれか。記号で答えよ。/n① 𝑓(𝑥)=max(0,𝑥)/n② 𝑓(𝑥)=min(0,𝑥)/n③ 𝑓(𝑥)=(1+𝑒^(−𝑥))^(−1)/n④ 𝑓(𝑥)=(1−𝑒^(−𝑥))^(−1)",
    "type": "descriptive",
    "fields_count": 2,
    "answer_groups": [
      ["1", "①"],
      ["3", "③"]
    ],
    "required_groups": 2,
    "explanation": "ReLU（Rectified Linear Unit）関数は、入力が0以下のときは0を出力し、0より大きいときはそのままの値を出力する活性化関数です。これは、選択肢①の「𝑓(𝑥)=max(0,𝑥)」で表されます。一方、シグモイド関数は、入力値を0から1の範囲に圧縮するS字型の関数で、選択肢③の「𝑓(𝑥)=(1+𝑒^(−𝑥))^(−1)」で表されます。"
  },
  {
    "type": "essay",
    "question": "活性化関数 𝑓 を使用しない場合、以下に示すニューラルネットワークAは、ニューラルネットワークA' に等価変換することができる。ニューラルネットワークAのパラメータ 𝐖(0,1) 、𝐖(1,2)、𝐛(1) 、𝐛(2) が以下のように与えられるとき、それと等価なニューラルネットワークA' のパラメータ 𝐖′ および 𝐛′ の値を求めよ。",
    "image": "./images/4-2.png",
    "exampleAnswer": "W'=[[0.32,0.8],[0.05,0.5]]\nb'=[0.38,0.1]",
    "explanation": "この問題は自己採点です。あなたの回答が正しいかどうか、模範解答を参考に確認してみましょう。"
  },
  {
    "type": "fill-in-blank",
    "question": "ア： [___] , イ： [___] , ウ： [___]",
    "image": "./images/4-3.png",
    "answers": [
      "2",
      "0",
      "1"
    ],
    "explanation": "大学入学共通テスト（＝皆さんと同学年の高校3年生が受験することになる試験）の「情報」から第1問問4です。"
  }
]